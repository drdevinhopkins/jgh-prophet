{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Facebook's Prophet library already included in Colab\n",
    "#!pip install fbprophet\n",
    "#Install World Weather Online library and import other dependencies:\n",
    "#!pip install wwo-hist\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fbprophet import Prophet\n",
    "from fbprophet.diagnostics import cross_validation\n",
    "from datetime import datetime, timedelta\n",
    "import requests\n",
    "from wwo_hist import retrieve_hist_data\n",
    "from datetime import date\n",
    "import pytz\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pkl_path = \"jgh-prophet-19-12-22.pkl\"\n",
    "\n",
    "# read the Prophet model object\n",
    "with open(pkl_path, 'rb') as f:\n",
    "    m = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fbprophet.forecaster.Prophet at 0x120e06090>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wwofuture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Retrieving weather data for Montreal\n",
      "\n",
      "\n",
      "Time elapsed (hh:mm:ss.ms) 0:00:00.577126\n",
      "\n",
      "\n",
      "export Montreal completed!\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequency = 24\n",
    "api_key = '3d51d04f983a478e90f164916191012'\n",
    "location_list = ['Montreal']\n",
    "retrieve_future_data(api_key,location_list,frequency,location_label = False, export_csv = True, store_df = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib\n",
    "import urllib.parse\n",
    "import json\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "##################################\n",
    "# function to unnest json for each month\n",
    "def extract_json_weather_data(data):\n",
    "    num_days = len(data)\n",
    "    # initialize df_month to store return data\n",
    "    #df_month = pd.DataFrame()\n",
    "    for i in range(num_days):\n",
    "        # extract this day\n",
    "        d = data[i]\n",
    "        # astronomy data is the same for the whole day\n",
    "        astr_df = pd.DataFrame(d['astronomy'])\n",
    "        # hourly data; temperature for each hour of the day\n",
    "        hourly_df = pd.DataFrame(d['hourly'])\n",
    "        # this wanted_key will be duplicated and use 'ffill' to fill up the NAs\n",
    "        wanted_keys = ['date', 'maxtempC', 'mintempC', 'totalSnow_cm', 'sunHour', 'uvIndex'] # The keys you want\n",
    "        subset_d = dict((k, d[k]) for k in wanted_keys if k in d)\n",
    "        this_df = pd.DataFrame(subset_d,index=[0])        \n",
    "        df = pd.concat([this_df.reset_index(drop=True), astr_df], axis=1)\n",
    "        # concat selected astonomy columns with hourly data\n",
    "        df = pd.concat([df,hourly_df], axis=1)\n",
    "        df = df.fillna(method='ffill')\n",
    "        # make date_time columm to proper format\n",
    "        # fill leading zero for hours to 4 digits (0000-2400 hr)\n",
    "        df['time'] = df['time'].apply(lambda x: x.zfill(4))\n",
    "        # keep only first 2 digit (00-24 hr) \n",
    "        df['time'] = df['time'].str[:2]\n",
    "        # convert to pandas datetime\n",
    "        df['ds'] = pd.to_datetime(df['date'] + ' ' + df['time'])\n",
    "        # keep only interested columns\n",
    "        col_to_keep = ['ds', 'maxtempC', 'mintempC', 'totalSnow_cm', 'sunHour', 'uvIndex', \n",
    "               'moon_illumination', \n",
    "               'DewPointC',  'FeelsLikeC', 'HeatIndexC', 'WindChillC', 'WindGustKmph',\n",
    "               'cloudcover', 'humidity', 'precipMM', 'pressure', 'tempC', 'visibility',\n",
    "               'winddirDegree', 'windspeedKmph']\n",
    "        df = df[col_to_keep]\n",
    "        #df_month = pd.concat([df_month,df])\n",
    "    #return(df_month)\n",
    "    return(df)\n",
    "\n",
    "##################################\n",
    "#function to retrive data by date range and location\n",
    "#default frequency = 1 hr\n",
    "#each month costs 1 request (free trial 500 requests/key, as of 30-May-2019)\n",
    "def retrieve_weather_data(api_key,location,frequency):\n",
    "    \n",
    "    #start_time = datetime.now()\n",
    "    \n",
    "    # create list of months, convert to month begins (first day of each month)\n",
    "    #list_mon_begin= pd.date_range(start_date,end_date, freq='1M')-pd.offsets.MonthBegin(1)\n",
    "    # convert to Series and append first day of the last month\n",
    "    #list_mon_begin = pd.concat([pd.Series(list_mon_begin), pd.Series(pd.to_datetime(end_date,infer_datetime_format=True).replace(day=1))], ignore_index=True)\n",
    "    # change the begin date to start_date\n",
    "    #list_mon_begin[0] = pd.to_datetime(start_date,infer_datetime_format=True)\n",
    "    \n",
    "    # create list of months, convert to month ends (last day of each month)\n",
    "    #list_mon_end = pd.date_range(start_date,end_date, freq='1M')-pd.offsets.MonthEnd(0)\n",
    "    # convert to Series and append the end_date\n",
    "    #list_mon_end = pd.concat([pd.Series(list_mon_end), pd.Series(pd.to_datetime(end_date,infer_datetime_format=True))], ignore_index=True)\n",
    "    \n",
    "    # count number of months to be retrieved\n",
    "    #total_months = len(list_mon_begin)\n",
    "\n",
    "    # initialize df_hist to store return data\n",
    "    weather_df = pd.DataFrame()\n",
    "    #for m in range(total_months):\n",
    "        \n",
    "        #start_d =str(list_mon_begin[m])[:10]\n",
    "        #end_d =str(list_mon_end[m])[:10]\n",
    "        #print('Currently retrieving data for '+location+': from '+start_d+' to '+end_d)\n",
    "        \n",
    "    url_page = 'http://api.worldweatheronline.com/premium/v1/weather.ashx?key='+api_key+'&q='+location+'&format=json&num_of_days=15'+'&tp='+str(frequency)\n",
    "    json_page = urllib.request.urlopen(url_page)\n",
    "    json_data = json.loads(json_page.read().decode())\n",
    "    data= json_data['data']['weather']\n",
    "       # call function to extract json object\n",
    "    weather_df = extract_json_weather_data(data)\n",
    "    #df_hist = pd.concat([df_hist,df_this_month])\n",
    "        \n",
    "    #time_elapsed = datetime.now() - start_time\n",
    "    #print('Time elapsed (hh:mm:ss.ms) {}'.format(time_elapsed))\n",
    "    return(df_hist)\n",
    "\n",
    "##################################\n",
    "#main function to retrive the data by location list\n",
    "def retrieve_future_data(api_key,location_list,frequency,location_label = False, export_csv = True, store_df = False):\n",
    "    result_list = []\n",
    "    for location in location_list:\n",
    "        print('\\n\\nRetrieving weather data for '+location+'\\n\\n')\n",
    "        df_this_city = retrieve_weather_data(api_key,location,frequency)\n",
    "        \n",
    "        if (location_label == True):\n",
    "        # add city name as prefix to the colnames\n",
    "            df_this_city = df_this_city.add_prefix(location+'_')\n",
    "            df_this_city.columns.values[0] = 'date_time'    \n",
    "        \n",
    "        if (export_csv == True):\n",
    "            df_this_city.to_csv('./'+location+'.csv', header=True, index=False) \n",
    "            print('\\n\\nexport '+location+' completed!\\n\\n')\n",
    "        \n",
    "        if (store_df == True):\n",
    "        # save result as object in the work space\n",
    "            result_list.append(df_this_city)\n",
    "    return(result_list)\n",
    "##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
